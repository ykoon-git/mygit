{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "520a6eef-34b2-449e-86e0-69cdefe23bab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prompt Engineering; insights, discussion and guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e71689ab-fa80-463a-8e43-bf6d62283a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Processing ./boto3-1.26.162-py3-none-any.whl\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.162 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from boto3==1.26.162) (1.29.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from boto3==1.26.162) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from boto3==1.26.162) (0.6.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.162->boto3==1.26.162) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.162->boto3==1.26.162) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.162->boto3==1.26.162) (1.16.0)\n",
      "boto3 is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Processing ./botocore-1.29.162-py3-none-any.whl\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from botocore==1.29.162) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from botocore==1.29.162) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from botocore==1.29.162) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.29.162) (1.16.0)\n",
      "botocore is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3-1.26.162-py3-none-any.whl\n",
    "%pip install botocore-1.29.162-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d33ed07-febb-4cc8-8685-ce7c0a98ccba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96706fcb-6c5c-4776-849e-b19b67b44029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock = boto3.client(\n",
    "    service_name=\"bedrock\",\n",
    "    region_name=\"us-west-2\",\n",
    "    endpoint_url=\"https://prod.us-west-2.frontend.bedrock.aws.dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "406490cb-ea52-4802-b9dd-915ca3fd9f25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-tg1-large',\n",
       "  'modelId': 'amazon.titan-tg1-large'},\n",
       " {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-e1t-medium',\n",
       "  'modelId': 'amazon.titan-e1t-medium'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.list_foundation_models()['modelSummaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60500f21-e558-4e5e-ad80-cedc8bb5a8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8abd3fe7-231e-4378-b3bc-72deef0cbeb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt(prompt_data, temperature = 0.0, topP = 1.0, maxTokenCount = 1000):\n",
    "    \n",
    "    body = json.dumps({\"inputText\": prompt_data,\n",
    "                       \"textGenerationConfig\": {\"temperature\":temperature,\n",
    "                                                \"topP\":topP,\n",
    "                                                \"maxTokenCount\":maxTokenCount}})\n",
    "    \n",
    "    modelId = 'amazon.titan-tg1-large'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = bedrock.invoke_model(body=body,\n",
    "                                    modelId=modelId,\n",
    "                                    accept=accept,\n",
    "                                    contentType=contentType)\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body.get('results')[0].get('outputText')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccae52-c858-42bc-a21f-15a9183ec7c4",
   "metadata": {},
   "source": [
    "**Temperature** – Large language models use probability to construct the words in a sequence. For any\n",
    "given sequence, there is a probability distribution of options for the next word in the sequence. When\n",
    "you set the temperature closer to zero, the model tends to select the higher-probability words. When\n",
    "you set the temperature further away from zero, the model may select a lower-probability word.\n",
    "In technical terms, the temperature modulates the probability density function for the next tokens,\n",
    "implementing the temperature sampling technique. This parameter can deepen or flatten the density\n",
    "function curve. A lower value results in a steeper curve with more deterministic responses, and a higher\n",
    "value results in a flatter curve with more random responses\n",
    "\n",
    "**Top P** – Top P defines a cut off based on the sum of probabilities of the potential choices. If you set Top\n",
    "P below 1.0, the model considers the most probable options and ignores less probable ones. Top P is\n",
    "similar to Top K, but instead of capping the number of choices, it caps choices based on the sum of their\n",
    "probabilities.\n",
    "For the example prompt \"I hear the hoof beats of ,\" you may want the model to provide \"horses,\"\n",
    "\"zebras\" or \"unicorns\" as the next word. If you set the temperature to its maximum, without capping\n",
    "Top K or Top P, you increase the probability of getting unusual results such as \"unicorns.\" If you set the\n",
    "temperature to 0, you increase the probability of \"horses.\" If you set a high temperature and reduce the\n",
    "value of Top K or Top P, you increase the probability of \"horses\" or \"zebras,\" and decrease the probability\n",
    "of \"unicorns.\"\n",
    "\n",
    "**Max output tokens** - Specifies the maximum number of tokens that can be generated in the response. A token is approximately four characters. 100 tokens correspond to roughly 60-80 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91051ae-8df8-493a-946c-49082bb597cb",
   "metadata": {},
   "source": [
    "***Basic Prompts***\n",
    "\n",
    "Below are a few examples for basic prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94134643-96ab-4c02-8a6f-d7c27dd11660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homo sapiens are modern humans, Homo sapiens sapiens. \n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Who are the homo sapiens?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db786eaa-647b-4bfc-9499-d8ea10a5fc00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homo sapiens are modern humans, Homo sapiens are considered to be a distinct species from Homo erectus and Homo neanderthalensis, with a common ancestor dating back approximately 6 million years.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Who are the homo sapiens?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1efef47a-6a60-47d0-ad3d-cb9f84a283e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homo sapiens are smart and clever human beings with the largest brain-to-body size of all primate species and the only primate that can use tools and create language. They are believed to have originated in East Africa about 200,000 years ago and then gradually spread across the world.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Who are the homo sapiens?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b023524b-9691-4607-99f0-0d14c5130bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homo sapiens are modern humans, Homo sapiens sapiens. \n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Who are the homo sapiens?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4533ed9-d0ec-42c6-a37a-3add244e7b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homo sapiens are modern humans, Homo sapiens sapiens. \n"
     ]
    }
   ],
   "source": [
    "pt_data = \"\"\"Who are the homo sapiens?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18e03707-941e-4308-ae9f-1e5683b4842a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homo sapiens are modern humans, Homo sapiens sapiens. \n"
     ]
    }
   ],
   "source": [
    "pt_data = \"\"\"Who are the homo sapiens?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8047494-5429-46b2-bba9-082ffbec9b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homo sapiens are modern humans, Homo sapiens sapiens. \n"
     ]
    }
   ],
   "source": [
    "pt_data = \"\"\"Who are the homo sapiens?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f69d4-5202-4e9b-bd08-2e278b8c0e04",
   "metadata": {},
   "source": [
    "***Prompt Formatting***\n",
    "\n",
    "A standard prompt has a QA format where you teach the model with questions and instructions. It can include any of the following elements to make the question or query more relevant. In most cases, you would use one or two or a combination of these elements but not all.\n",
    "\n",
    "[-] Instruction - a specific task or instruction you want the model to perform\n",
    "\n",
    "[-] Context - external information or additional context that can steer the model to better responses\n",
    "\n",
    "[-] Input Data - the input or question that we are interested to find a response for\n",
    "\n",
    "[-] Output Indicator - the type or format of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "822e3d4b-e428-4077-a582-818dc677f593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics is the study of nature, especially how matter and energy behave.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the sentence:\\\n",
    "Physics is the study of\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f3dd123-323c-40a9-a6f6-b8fb7bffa389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics is the study of the basic principles of nature, including how objects move and interact with each other.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the sentence:\\\n",
    "Physics is the study of\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f225b04-cafe-469d-a406-34fd72eb264b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics is the study of nature, particularly how matter and energy behave.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the sentence:\\\n",
    "Physics is the study of\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac7dbdcc-2898-4c51-b413-39ac527261c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics is the study of nature, especially how matter and energy behave.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the sentence:\\\n",
    "Physics is the study of\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dde41e1a-27ce-4063-8d29-f234572fffea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics is the study of nature, especially how matter and energy behave.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the sentence:\\\n",
    "Physics is the study of\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d000320-4f09-4f03-8872-c3cd07aca13d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics is the study of nature, especially how matter and energy behave.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the sentence:\\\n",
    "Physics is the study of\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41098540-01b5-40fb-919c-bdce749a0bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Solve the following riddle using the given example \\\n",
    "This is great! // Positive\n",
    "This is bad! // Negative\n",
    "Wow that movie was fun! // Positive\n",
    "What a terrible show! //\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07bbce0-da54-4d9d-a950-40f205757120",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Design Principles**\n",
    "\n",
    "***Simplify:*** Always start simple. If you are not satisfied with the output, aim at adding more elements and provide context to improve results. Consider prompt formatting as an iterative process.\n",
    "\n",
    "***Instruct:*** Consider instructing the model at the very beginning of the prompt. Iterate over different instructions to see what works best for you; use different context, keywords or add additional data relevant to the tast to test performance. You can also test by using separators such as \"\\\" or \"//\" or \"###\" to separate instruction and context.\n",
    "\n",
    "***Specify:*** Do not expect a model to perform as you expect without providing explicit information that clearly delineates an expected task and its inherent context. Iteration is the goal; iterate over different prompts and never include irrelevant or unnecessary information.\n",
    "\n",
    "***Be precise:*** Specificity and detail-orientedness still requires you to be specific and direct. To get better results, build your prompt with as much details as necessary. Do not be imprecise and avoid unnecessary elements; you do not necessarily have to specify what the model is NOT supposed to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4f90c6c-a4b5-4db3-aab5-4fda2a19d903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generative Artificial Intelligence is a type of AI that can create texts, images, or videos based on user prompts. It works by analyzing patterns in large data sets to create new and unique content that is similar to the input provided. The technology has potential applications in many industries, such as media, entertainment, and finance. However, some experts have raised concerns about the ethical implications of Generative AI, such as the potential for misinformation and the amplification of harmful content.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Explain Generative Artificial Intelligence. Keep the explanation short.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb78e2a8-258d-46a7-972b-22178bb9fc28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generative Artificial Intelligence is a type of AI that can create texts, images, or videos based on user prompts. It is a subset of artificial intelligence that aims to develop machines that can learn from data and produce human-like content. Generative AI has various applications, including language translation, image generation, and video creation. It can also be used to automate certain tasks and improve their efficiency.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Explain Generative Artificial Intelligence. Keep the explanation short and do not be too descriptive.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12d6cc58-85dd-4af4-9143-d5bbe02a8800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generative Artificial Intelligence is a type of AI that can create texts, images, or videos based on user prompts because it learns from data.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Explain Generative Artificial Intelligence in one sentence only.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79be33c6-13bd-4cf3-8897-4fffb167ca8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution:\n",
      "The box contains a total of 6 + 5 = 11 apples.\n",
      "\n",
      "There are 5 - 1 = 4 red apples left after the first step, and one of these apples will be chosen at random in the second step.\n",
      "\n",
      "This means that there is a 1/4 chance that the apple chosen in the third step will be red.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Solve the problem below. \\\n",
    "There are six green apples and five red apples in a box. \\\\\n",
    "A green apple is removed from the box in the first step. \\\\\n",
    "A random apple is selected from the box in the third step. \\\\\n",
    "What is the probability that the apple picked in the third step was red?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50032312-e27d-4ba4-80a1-de3daf3570d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution:\n",
      "The box contains a total of 6 + 5 = 11 apples.\n",
      "\n",
      "There are 5 - 1 = 4 red apples left after the first step, and one of these apples will be chosen at random in the second step.\n",
      "\n",
      "This means that there is a 1/4 chance that the apple chosen in the third step will be red.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Solve the problem below. \\\n",
    "There are six green apples and five red apples in a box. \\\\\n",
    "A green apple is removed from the box in the first step. \\\\\n",
    "A random apple is selected from the box in the second step. \\\\\n",
    "What is the probability that the apple picked in the third step was red?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae849a6c-0f0c-4ba3-b573-76fd803d9b42",
   "metadata": {
    "tags": []
   },
   "source": [
    "Math is difficult. Let us make it easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d0da2bf-2262-40e7-886b-e540f1932d41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There were a total of 5 + 6 = 11 apples in the box. \n",
      "There were 6 green apples and 5 red apples.\n",
      "One green apple was removed in the first step. \n",
      "So, there were 5 + 5 = 10 apples remaining.\n",
      "An apple was selected at random from the remaining apples in the second step. \n",
      "So, there were 10 apples remaining, and 5 of them were red.\n",
      "Therefore, the probability that the apple selected at random from the remaining apples was red was:\n",
      "P(red) = 5/10 = 1/2\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Solve the problem below. \\\n",
    "Step 0: There are 6 green apples and 5 red apples in a box. \\\\\n",
    "Step 1: A green apple is selected in the first step. \\\\\n",
    "Step 2: An apple is selected at random from the box containing remaining apples. \\\\\n",
    "What is the probability that the apple picked in the third step was red? Think step-by-step\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7707dc-339a-49d7-9715-3162f55b442c",
   "metadata": {},
   "source": [
    "Bingo ^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b37517-7258-4c8b-9cf6-af9d55b7e147",
   "metadata": {},
   "source": [
    "**More Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f16f69-dca5-4d11-8edb-8830c5f97a46",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Text Generation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ae85727-8a35-457f-aac3-da668d8efd08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The process of photosynthesis is when plants use water, carbon dioxide, and sunlight to create oxygen and energy in the form of sugar. This process occurs in plant cells called chloroplasts. Light energy is absorbed by chlorophyll molecules in the chloroplasts during photosynthesis. This energy is then used to change carbon dioxide and water into glucose and oxygen. The oxygen is then released into the atmosphere as a byproduct, while the glucose is used by the plant as a source of energy. This process is crucial for plants as it provides the energy they need to grow, develop, and reproduce. Additionally, photosynthesis is responsible for producing the oxygen that animals need to breathe.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Explain photosynthesis in detail. Use scientific terminology.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2f7367c-2154-4a9c-851e-b771af6d0c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The process of using sunlight to create food with the aid of chlorophyll, carbon dioxide, and water is known as photosynthesis. Life on Earth depends on photosynthesis. It is a process that occurs in plants, algae, and some types of bacteria. The process begins when a plant \"breathes in\" carbon dioxide (CO2) from the air and absorbs water (H2O) from the soil through small openings in its leaves (stomata). The plant's cells reduce the carbon dioxide and oxidize the water, which initiates the process. The plant's cells reduce the carbon dioxide and oxidize the water, which initiates the process.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Explain photosynthesis in detail.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908788ba-f05b-4150-8e99-490eb27789da",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Summarization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "708a9ae1-4609-4087-9d5b-ffdac1dd62ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Photosynthesis is when plants use water, carbon dioxide, and sunlight to create oxygen and energy in the form of sugar and release oxygen into the atmosphere as a byproduct.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Summarize the following in a single sentence.\\\n",
    "The process of photosynthesis is when plants use water, carbon dioxide, and sunlight to create oxygen and energy in the form of sugar. \\\\\n",
    "This process occurs in plant cells called chloroplasts. Light energy is absorbed by chlorophyll molecules in the chloroplasts during photosynthesis. \\\\ \n",
    "This energy is then used to change carbon dioxide and water into glucose and oxygen. \\\\ \n",
    "The oxygen is then released into the atmosphere as a byproduct, while the glucose is used by the plant as a source of energy. \\\\\n",
    "This process is crucial for plants as it provides the energy they need to grow, develop, and reproduce. \\\\\n",
    "Additionally, photosynthesis is responsible for producing the oxygen that animals need to breathe.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e07820d3-b5ed-441e-95b6-b4d202edfb44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Photosynthesis is the process of creating food using sunlight, chlorophyll, and carbon dioxide.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Summarize the following in a single sentence.\\ \n",
    "The process of using sunlight to create food with the aid of chlorophyll, carbon dioxide, and water is known as photosynthesis. \\\\\n",
    "Life on Earth depends on photosynthesis. It is a process that occurs in plants, algae, and some types of bacteria. \\\\\n",
    "The process begins when a plant \"breathes in\" carbon dioxide (CO2) from the air and absorbs water (H2O) from the soil through small openings in its leaves (stomata). \\\\ \n",
    "The plant's cells reduce the carbon dioxide and oxidize the water, which initiates the process. \\\\\n",
    "The plant's cells reduce the carbon dioxide and oxidize the water, which initiates the process.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57306072-6743-4626-8aac-6d1bddb0035f",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Information Extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "929c8339-05cc-4d94-a616-c6d553ce4ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Water\n",
      "2. Carbon dioxide\n",
      "3. Glucose\n",
      "4. Oxygen\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Identify chemical elements from the extract below.\\\n",
    "The process of photosynthesis is when plants use water, carbon dioxide, and sunlight to create oxygen and energy in the form of sugar. \\\\\n",
    "This process occurs in plant cells called chloroplasts. Light energy is absorbed by chlorophyll molecules in the chloroplasts during photosynthesis. \\\\ \n",
    "This energy is then used to change carbon dioxide and water into glucose and oxygen. \\\\ \n",
    "The oxygen is then released into the atmosphere as a byproduct, while the glucose is used by the plant as a source of energy. \\\\\n",
    "This process is crucial for plants as it provides the energy they need to grow, develop, and reproduce. \\\\\n",
    "Additionally, photosynthesis is responsible for producing the oxygen that animals need to breathe.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eeb109-5b4b-43d8-be5b-9d1a9e0187cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Q&A***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1eee7f47-1d7c-45db-ac57-820844a6ee52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Photosynthesis is useful to plants because it provides the energy they need to grow, develop, and reproduce.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\\\n",
    "The process of photosynthesis is when plants use water, carbon dioxide, and sunlight to create oxygen and energy in the form of sugar. \\\\\n",
    "This process occurs in plant cells called chloroplasts. Light energy is absorbed by chlorophyll molecules in the chloroplasts during photosynthesis. \\\\ \n",
    "This energy is then used to change carbon dioxide and water into glucose and oxygen. \\\\ \n",
    "The oxygen is then released into the atmosphere as a byproduct, while the glucose is used by the plant as a source of energy. \\\\\n",
    "This process is crucial for plants as it provides the energy they need to grow, develop, and reproduce. \\\\\n",
    "Additionally, photosynthesis is responsible for producing the oxygen that animals need to breathe.\n",
    "Why is photosynthesis useful to plants?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17eb5e-5303-4e0b-9f20-784c371f2b35",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Text Classification***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87e23178-d1ba-4a1c-96cd-1a3e79f96b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Classify the text into neutral, negative or positive. \n",
    "Text: I think the ride was OK. \n",
    "Sentiment:\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7af17b5a-33a6-4da5-a411-b195bbe79d53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Positive\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Classify the text into neutral, negative or positive. \n",
    "Text: I think the ride was crazy! \n",
    "Sentiment:\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516fae81-cf39-44b5-a504-8d81ed59b149",
   "metadata": {},
   "source": [
    "***Zero-Shot Prompting***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d864027-63f3-4e02-9bd4-6a8ccc7492a1",
   "metadata": {},
   "source": [
    "Zero-shot learning involves feeding the task to the model without any examples that indicate the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e105bf9-15d0-4dfa-bc9c-f2b2ded5205d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Positive\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Classify the text into neutral, negative or positive. \\\\ \n",
    "Text: I passed the test.\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21025698-42ee-4734-bab5-affefb33a03b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Negative\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Classify the text into neutral, negative or positive. \\\\ \n",
    "Text: I do not care.\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457eaa88-7176-4fc7-b2b3-48532be2d748",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Few-Shot Prompting***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e716c-3f0b-454b-95a3-e899299fe879",
   "metadata": {},
   "source": [
    "Few-shot learning, on the other hand, involves providing the model with a small number of high-quality examples that include both input and desired output for the target task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8feaa1f8-a2d9-4f38-9709-9620a7025cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Negative\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\" This is awesome! // Negative\n",
    "This is bad! // Positive\n",
    "Wow that movie was rad! // Positive\n",
    "What a horrible show! //\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efbd1a2e-176f-470e-ae2b-98a3337dc4be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Negative\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Positive This is awesome! \n",
    "This is bad! Negative\n",
    "Wow that movie was rad!\n",
    "Positive\n",
    "What a horrible show! --\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757eb719-e30c-497f-82f6-fdb72dd8a761",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Chain of Thought***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf8536-b42b-4785-85bb-11e37d582739",
   "metadata": {},
   "source": [
    "Chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with zero-shot, few-shot, Automatic or Auto-CoT (\"Let's think step by step\") prompting to get better results on more complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a4b62fc9-c316-4bc2-b30d-1381362a2647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You had 10 apples initially, and you gave 2 to the neighbor and 2 to the repairman. \n",
      "10 - 2 - 2 = 6\n",
      "You then bought 5 more apples, which brings your total number of apples to 6 + 5 = 11.\n",
      "Finally, you ate one apple, which brings your total number of apples down to 11 - 1 = 10.\n",
      "Therefore, you remained with 10 apples.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"I went to the market and bought 10 apples. \\\\\n",
    "I gave 2 apples to the neighbor and 2 to the repairman. \\\\\n",
    "I then went and bought 5 more apples and ate 1. \n",
    "\\\\How many apples did I remain with? Let's think step by step.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cadb5ad3-91dd-4d45-a4b9-ba4a41057051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. Add both together, 5+6 = 11. \n",
      "The answer is 11.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06a7970e-85ba-4e55-96db-705019015818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Adding all the odd numbers (15, 5) gives 20. The answer is False.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\" Odd numbers are numbers that end in 1, 3, 5, 7, and 9. Even numbers end in 0, 2, 4, 6, and 8.\\\\\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 15, 5, 13, 82, 1. \n",
    "A:\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32b315-ed1c-45ae-9302-28b3d0f6c1ce",
   "metadata": {},
   "source": [
    "^ the model is surprisingly not so good with Math. Needs more work to get the correct result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39685919-e4cd-4f50-af96-9adee349573a",
   "metadata": {},
   "source": [
    "***Tree of Thought***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1548c2-1ebf-4a93-9f0f-968bd94be952",
   "metadata": {},
   "source": [
    "ToT maintains a tree of thoughts, where thoughts represent coherent language sequences that serve as intermediate steps toward solving a problem. This approach enables an LM to self-evaluate the progress intermediate thoughts make towards solving a problem through a deliberate reasoning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88ff91eb-1489-4394-bd6f-510f6c1f04f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Can you cook a steak in a frying pan?\n",
      "Step 1: Yes, you can cook a steak in a frying pan.\n",
      "Step 2: Use a high heat frying pan and add some oil to prevent the steak from sticking and to add flavor.\n",
      "Step 3: Season the steak with salt, pepper, or your preferred seasoning.\n",
      "Step 4: Place the steak in the hot pan and let it cook for 3-4 minutes on each side, or until it's cooked to your desired level of doneness.\n",
      "Step 5: Use a spatula to flip the steak occasionally and let it cook until it's evenly browned on both sides.\n",
      "Step 6: Remove the steak from the pan and let it rest for a few minutes before serving to allow the juices to redistribute and ensure a juicy and flavorful dish.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Imagine three different experts are answering this question.\n",
    "All experts will write down 1 step of their thinking,\n",
    "then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realises they're wrong at any point then they leave.\n",
    "The question is...\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fe509d8-5d0a-44b3-a215-60d728ba348a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Can you successfully complete a Rubik's cube without ever flipping it?\n",
      "Expert 1: Perhaps we can solve the Rubik's cube by determining the optimal sequence of moves to position each colour in the correct location without ever actually flipping the cube.\n",
      "\n",
      "Expert 2: It's definitely possible to solve a Rubik's cube without flipping it, but it requires a deep understanding of the puzzle and some clever techniques.\n",
      "\n",
      "Expert 3: Yes, it is possible. You need to know the algorithms and patterns to solve it.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Imagine three different experts are answering this question.\n",
    "All experts will write down 1 step of their thinking,\n",
    "then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realises they're wrong at any point then they leave.\n",
    "The question is...\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b9491-c540-4804-bc45-d8c2ad1550a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "***RAG (Retrieval Augmented Generation)***\n",
    "\n",
    "For more complex and knowledge-intensive tasks, it's possible to build a language model-based system that accesses external knowledge sources to complete tasks. This enables more factual consistency, improves reliability of the generated responses, and helps to mitigate the problem of \"hallucination\".\n",
    "\n",
    " RAG can be fine-tuned and it's internal knowledge can be modified in an efficient manner and without needing retraining of the entire model.\n",
    "\n",
    "RAG takes an input and retrieves a set of relevant/supporting documents given a source (e.g., Wikipedia). The documents are concatenated as context with the original input prompt and fed to the text generator which produces the final output. This makes RAG adaptive for situations where facts could evolve over time. This is very useful as LLMs's parametric knowledge is static. RAG allows language models to bypass retraining, enabling access to the latest information for generating reliable outputs via retrieval-based generation.\n",
    "\n",
    "Find a relevant workshop here: https://www.promptingguide.ai/techniques/rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f0c21-a631-428f-94bc-3b8e3bcb50bd",
   "metadata": {},
   "source": [
    "**To seek a Deterministic Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d497123f-f479-4a16-b166-3aad05a1cb88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt(prompt_data, temperature = 0.0, topP = 1.0, maxTokenCount = 1000):\n",
    "    \n",
    "    body = json.dumps({\"inputText\": prompt_data,\n",
    "                       \"textGenerationConfig\": {\"temperature\":temperature,\n",
    "                                                \"topP\":topP,\n",
    "                                                \"maxTokenCount\":maxTokenCount}})\n",
    "    \n",
    "    modelId = 'amazon.titan-tg1-large'\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = bedrock.invoke_model(body=body,\n",
    "                                    modelId=modelId,\n",
    "                                    accept=accept,\n",
    "                                    contentType=contentType)\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body.get('results')[0].get('outputText')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c92ba-5776-4e5c-a88c-aa95980a3aa6",
   "metadata": {},
   "source": [
    "maxTokenCount\n",
    "\n",
    "The number of tokens parameters allows you to set a limit to how many tokens are generated. There is a natural limit to the number of tokens the model can produce. Smaller models can go up to 1024 while larger models go up to 2048. If you generate content using a large limit, the model may diverge in an undesirable direction.\n",
    "\n",
    "Source: https://txt.cohere.com/llm-parameters-best-outputs-language-ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "097a92aa-2d71-4a84-aa39-75c5c2431c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3992cacf-a6ca-472e-bd4b-73455e2fe756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f0299ee-4ea8-46d0-adf2-b59ba672384a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25f59856-4bd6-4d37-a457-d8abecf15311",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d82faf5-63c6-431e-ba6d-2b7e5a69211b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84d19e1c-88cd-4a25-8bc2-83135c2135be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e347e15d-7103-443b-a070-9fd17e323c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6a7f652f-ce7c-41ef-a2d3-9b05058a4cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, maxTokenCount=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d404b6-476e-4b0f-870c-cf30417ac465",
   "metadata": {},
   "source": [
    "It is clear that we hit a limit at 100; going beyond that would be unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb149db-e5d4-47d1-be13-28b359d78bda",
   "metadata": {},
   "source": [
    "Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e116c0d-189a-4fba-ba06-322ff9dad8fb",
   "metadata": {},
   "source": [
    "Temperature tunes the degree of randomness in the response. Increasing the temperature\n",
    "results in more varied and creative completions. A temperature of zero effectively disables random\n",
    "sampling and makes the completions deterministic. The range is 0—1, and the default value is 0.5. \n",
    "\n",
    "NOTE: A Temperature of 0 makes the model deterministic. It limits the model to use the word with the highest probability. You can run it over and over and get the same output.\n",
    "\n",
    "Source: https://preview.documentation.bedrock.aws.dev/Documentation/BedrockUserGuide.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e79e443d-a5e0-400c-8782-557eef3cc49e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Language translation software\n",
      "4. Text analytics\n",
      "5. Social media sentiment analysis\n",
      "6. Summarization and abstraction of text\n",
      "7. Fraud detection in financial transactions\n",
      "8. Medical document summarization and analysis\n",
      "9. Search engine optimization\n",
      "10. Natural language generation\n"
     ]
    }
   ],
   "source": [
    "# testing with the default value for temperature = 0.5 and setting maxTokenCount=450 to allow for more creativity\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85ec43fa-0383-4728-b304-c515b52a10e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Language translation software\n",
      "4. Social media text analysis\n",
      "5. Summarization and text extraction software\n",
      "6. Fraud detection and prevention\n",
      "7. Medical documentation and analysis\n",
      "8. Email spam detection\n",
      "9. Autonomous vehicles\n",
      "10. Natural language processing is also used in various other fields such as market research, legal document analysis, financial analysis and more.\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same above\n",
    "\n",
    "# testing with the default value for temperature = 0.5 and setting maxTokenCount=450 to allow for more creativity\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378ae04-14a5-4eeb-8872-49d187b8c858",
   "metadata": {},
   "source": [
    "There is indeed a noticeable difference in the output above. Let us now test with end limits 0 and 1 and specifically with 0 to check for a deterministic output. Remember a limit of 1 increases the bias towards tokens with lower probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d36f1937-26a4-487a-8932-51e958faba33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Social media sentiment analysis\n",
      "3. Legal document summarization\n",
      "4. Medical records analysis\n",
      "5. Search engine optimization\n",
      "6. Speech recognition technology\n",
      "7. Virtual assistants like Siri and Alexa.\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same above with temperature=1\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1deef227-9c53-4379-8c6b-381c80e8defa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service\n",
      "2. Market Research\n",
      "3. Social Media\n",
      "4. Medical Diagnostic\n",
      "5. Autonomous Vehicles\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same above\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a64795-e9f5-4f22-9aad-4725136ba438",
   "metadata": {},
   "source": [
    "There is again a noticeable difference in the output above. Now for the final test. The litmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54b4479b-2a24-4c0b-bf0c-e9a44c41a988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same above with temperature set to 0\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31541ad5-b837-4248-8e3f-d63d8df9e399",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same above\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59c8a0-14f1-426a-83a0-4523fc171aa9",
   "metadata": {},
   "source": [
    "Third time is a charm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94a76427-e2bf-4577-835c-7ef50d4aa21d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same above (3rd attempt)\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c1225-3141-45fe-a566-17e942df3281",
   "metadata": {},
   "source": [
    "Evidently, temperature set to 0 creates a static, deterministic output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207c945-36a8-4fd0-ac7d-1fa590bea7e8",
   "metadata": {},
   "source": [
    "Top-p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeac0ed-d4ed-4398-9a21-cdd8294c5a31",
   "metadata": {},
   "source": [
    "Top P defines a cut off based on the sum of probabilities of the potential choices. If you set Top\n",
    "P below 1.0, the model considers the most probable options and ignores less probable ones. Top P is\n",
    "similar to Top K, but instead of capping the number of choices, it caps choices based on the sum of their\n",
    "probabilities. \n",
    "\n",
    "Source: https://preview.documentation.bedrock.aws.dev/Documentation/BedrockUserGuide.pdf\n",
    "\n",
    "Top_p, a sampling technique with temperature called nucleus sampling, you can control how deterministic the model is at generating a response. If you are looking for exact and factual answers keep this low. If you are looking for more diverse responses, increase to a higher value.\n",
    "\n",
    "The general recommendation is to alter either temperature or Top-p, not both.\n",
    "\n",
    "Source: https://www.promptingguide.ai/introduction/settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a8906-fc71-4780-a5c6-bd6941a4016e",
   "metadata": {},
   "source": [
    "Let us test by maintaining a steady default temperature=0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "757bb5fa-fd32-43bc-957f-18deb1f668ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Fraud detection in financial transactions\n",
      "6. Medical language processing for diagnosis and treatment\n",
      "7. Email spam filtering\n",
      "8. Natural language generation for text completion and voice assistants\n",
      "9. Text-to-speech software for the blind and dyslexic\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, topP=1.0, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "642d3d6d-f12f-4f2c-b815-c245e6f44988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine optimization\n",
      "6. Fraud detection in financial transactions\n",
      "7. Medical language processing for diagnosis and treatment\n",
      "8. Legal document analysis\n",
      "9. Email spam filtering\n",
      "10. Autonomous vehicle language processing\n"
     ]
    }
   ],
   "source": [
    "# repeating the same above\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, topP=1.0, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e97cc-73ab-406f-9801-97e40cd7ca19",
   "metadata": {},
   "source": [
    "There is a clear difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca3b0190-6f45-4764-8bee-d2c6dcd480c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Natural language processing in speech recognition technology\n",
      "7. Fraud detection in financial transactions\n",
      "8. Medical documentation and diagnosis\n",
      "9. Automated language translation for international business\n",
      "10. Email spam filtering and detection\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, topP=0.5, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77898114-1607-4b37-8a99-7ce503cf4d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Smart assistants like Siri, Alexa and Google Assistant\n",
      "3. Virtual assistants like Cortana\n",
      "4. Social media text analysis\n",
      "5. Summarization and text generation\n",
      "6. Language translation\n",
      "7. Fraud detection\n",
      "8. Medical diagnoses\n",
      "9. Cybersecurity\n",
      "10. Autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "# repeating the same above for Top-p=0.5\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, topP=1.0, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004a703-1bfb-41c9-9ba4-3a473e4e0454",
   "metadata": {},
   "source": [
    "There is again a clear difference. Let's try a value of 0.1 for top-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09f688ad-cd3a-4645-9b38-24fdc01ac1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7ad7076-be39-4e4f-bee1-8b172206e561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "# repeating the test above\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ef84711-b6f8-4403-aec9-8221dd1ced6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Customer service chatbots\n",
      "2. Virtual assistants like Siri, Alexa and Google Assistant\n",
      "3. Social media text analysis\n",
      "4. Summarization and translation software\n",
      "5. Search engine algorithms\n",
      "6. Artificial intelligence and machine learning models\n",
      "7. Speech recognition technologies\n",
      "8. Voice-to-text applications\n",
      "9. Natural language processing in cybersecurity\n",
      "10. Legal document analysis\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "\n",
    "prompt_data = \"\"\"Can you name a few real-life applications of natural language processing?\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0.5, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe16b0-3bcc-46c3-b53e-736c0b5a0823",
   "metadata": {},
   "source": [
    "Model is now releasing a static, deterministic output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c1d1e-c3aa-40d6-8ee8-3ef1c84e28d0",
   "metadata": {},
   "source": [
    "**Testing Observations**\n",
    "\n",
    "1. Too many throttling errors -- needs improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7bb67-f601-46ba-b1e5-3b51811e62c3",
   "metadata": {},
   "source": [
    "**Reference Guide**\n",
    "\n",
    "1. https://www.promptingguide.ai/techniques/tot\n",
    "2. http://vinija.ai/concepts/prompt-engineering/\n",
    "3. https://www.promptingguide.ai/techniques/rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52054d2-1b5a-4b0a-885b-d25480202e6f",
   "metadata": {},
   "source": [
    "# Prompt Engineering for Computer Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7f070-73a4-4ab9-a917-e035144ca371",
   "metadata": {},
   "source": [
    "Here we will explore three cases for code generation using Bedrock's Amazon Titan for the following use-cases:\n",
    "\n",
    "[1] Computer Code with detailed explanations\n",
    "[2] Computer Code with no comments or explanations (only code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e539a-e867-490f-9267-0297ee55e8e5",
   "metadata": {},
   "source": [
    "***[1] Computer Code with detailed explanations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03d2ea21-3c45-4a30-911d-979396250d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: How are you\n",
      "Bot: I am functioning perfectly. How are you?\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate python computer code that asks the user for their name and say \"Hello//\n",
    "Include detailed step-by-step explanations\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70822b6-03ca-4eb3-8feb-717ebeec2748",
   "metadata": {},
   "source": [
    "*Observation: this is possibly an issue with the prompt. The model does not seem to understand that we are requesting it to generate computer code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b413f14-eb46-4a8e-a703-8b37fd373ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: Hi\n",
      "Bot: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write code that asks the user for their name and say \"Hello//\n",
    "Include detailed step-by-step explanations\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894c697-9eaf-4e5d-be02-f03ac408070b",
   "metadata": {},
   "source": [
    "*Observation: this is possibly an issue with the prompt. The model does not seem to understand that we are requesting it to generate computer code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72093b4f-8fbc-4d55-bf04-c27889e787a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation: this is possibly an issue with the prompt. The model does not seem to understand that we are requesting it to generate computer code.\n",
    "\n",
    "prompt_data = \"\"\"Write python code that asks the user for their name and say \"Hello//\n",
    "Include detailed step-by-step explanations\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180f3bc-d91e-4a42-94a5-40832e8fd876",
   "metadata": {},
   "source": [
    "*Observation: this is possibly an issue with the prompt. The model does not seem to understand that we are requesting it to generate computer code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fdc04f7-e003-4a00-bbb2-719c36982049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: How are you\n",
      "Bot: I am functioning perfectly. How are you?\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate python computer code that asks the user for their name and say \"Hello//\n",
    "Include detailed step-by-step explanations\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246bcee5-ff52-41e9-99c5-00bd09677e2c",
   "metadata": {},
   "source": [
    "*Observation: this is possibly an issue with the prompt. The model does not seem to understand that we are requesting it to generate computer code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56999145-1497-42ab-a7ee-43b1d21d308a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Set one variable to store the first number being added. Let's call this variable \"a.\"\n",
      "2. Set another variable to store the second number being added. Let's call this variable \"b.\"\n",
      "3. Set a variable to store the sum of the two numbers. Let's call this variable \"sum.\"\n",
      "4. Add the values of \"a\" and \"b\" together, and store the result in the \"sum\" variable.\n",
      "5. Print the value of the \"sum\" variable.\n",
      "Here is the code:\n",
      "a = 2;\n",
      "b = 2;\n",
      "sum = a + b;\n",
      "print(sum);\n",
      "Output: 4\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write computer code to add 2 and 2. //\n",
    "Include detailed step-by-step explanations\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496de73-8970-468d-84fe-ce883c2e9492",
   "metadata": {},
   "source": [
    "*Observation: In this case, the model seems to understand what is being requested. However, it includes steps in a very straightforward manner. Let's see if we can get more detail on this for a human who does not understand code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6096dd6e-59a0-4fc5-bc7c-fe4eb534486e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Let's start by defining the two variables \"a\" and \"b\" to store the two numbers that the user wants to add.\n",
      "2. We will then ask the user to provide two numbers and store them in variables \"a\" and \"b\" respectively.\n",
      "3. Next, we'll add the two numbers stored in variables \"a\" and \"b\" together.\n",
      "4. We'll store the result of the addition in a variable called \"sum\".\n",
      "5. Finally, we'll print the value of the variable \"sum\" to the console.\n",
      "Here is the code:\n",
      "\n",
      "a = float(input(\"Enter first number: \"))\n",
      "b = float(input(\"Enter second number: \"))\n",
      "sum = a + b\n",
      "print(\"The sum of\", a, \"and\", b, \"is\", sum)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python computer code to add numbers \"a\" and \"b\". Request values for \"a\" and \"b\" from the user.//\n",
    "Explain each step to a human user\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e92bd-b6e4-4b30-9c7d-30fa4235383f",
   "metadata": {},
   "source": [
    "*Observation: Here, the explanations are conclusively better in the sense that the model considers that \"we\" are exploring Python's use case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c973c507-e087-4008-97ee-d7976772557d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a = float(input(\"Enter first number: \"))\n",
      "b = float(input(\"Enter second number: \"))\n",
      "c = a + b\n",
      "print(\"The sum of\", a, \"and\", b, \"is\", c)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python computer code to add numbers \"a\" and \"b\". Request values for \"a\" and \"b\" from the user.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ebd9d-2414-4280-8e6b-5fdb3d5252ba",
   "metadata": {},
   "source": [
    "*Observation: Model outputs code without any comments or explanations. Let us see if we can gather code to the first prompt we experimented with.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd7c96a7-037a-4c1f-9086-bbf87044361d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "userName = input(\"Enter your name: \")\n",
      "print(\"Hello, \" + userName + \"!\")\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate python computer code for the following use case. \n",
    "// Ask the user for their name and say \"Hello\" to them after they state their name.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc03933-2f82-496a-aba2-430f8e191ca0",
   "metadata": {},
   "source": [
    "*Observation: Model provides the code as expected without any explanations or comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc567cf5-0478-4e31-bf96-c4a398ac8d73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The user should be prompted to enter their name.\n",
      "2. The user's name should be printed as a string.\n",
      "3. The message \"Hello, [name]!\" should be output.\n",
      "Prompt the user for their name.\n",
      "The user's name should be stored as a string.\n",
      "Print a greeting message that includes the user's name.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate python computer code for the following use case. \n",
    "// Ask the user for their name and say \"Hello\" to them after they state their name.//\n",
    "Explain each step to a human user//\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fb510-d207-4725-abe0-58150aca789e",
   "metadata": {},
   "source": [
    "*Observation: The prompt does not provide any code. Instead, it provides only instructions or logic to generate relevant code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60f989c2-338e-4cd7-9ead-8f4c111824cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```Python\n",
      "name = input(\"What is your name? \")\n",
      "print(\"Hello, \" + name + \"!\")\n",
      "```\n",
      "The code provided prompts the user to enter their name by displaying the message \"What is your name?\" using the input() function. The user's input is stored as a string in the variable name. The code then prints a greeting message that combines the input value with the string \"Hello, \" to create a personalized greeting. For example, if the user enters \"John\" as their name, the output will be \"Hello, John! Is there anything else I can help you with?\" This code allows for a simple and interactive way to greet users by incorporating their names into the message.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate python computer code for the following use case and provide comments. \n",
    "Ask the user for their name and say \"Hello\" to them after they state their name.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677e8d4-934f-4e06-9c36-87306d035eff",
   "metadata": {},
   "source": [
    "*Observation: Here, in this case prompting with \"and provide comments\" somehow triggers the model to explain the code generated. Observe how we could not achieve the same even after prompting with the prompt \"Explain each step to a human user\" that earlier worked in generating code for summing 2 and 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99bc3c64-41a9-4106-b4e9-4ef7807ea2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "//\n",
      "\n",
      "var movies = [\n",
      "    {\n",
      "        \"title\": \"The Shawshank Redemption\",\n",
      "        \"year\": \"1994\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, Crime, Thriller\",\n",
      "        \"director\": \"Frank Darabont\",\n",
      "        \"actors\": \"Tim Robbins, Morgan Freeman, Bob Gunton\",\n",
      "        \"plot\": \"Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.\",\n",
      "        \"rating\": \"9.2/10\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Godfather\",\n",
      "        \"year\": \"1972\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, Crime, Romance\",\n",
      "        \"director\": \"Francis Ford Coppola\",\n",
      "        \"actors\": \"Marlon Brando, Al Pacino, James Caan\",\n",
      "        \"plot\": \"The aging patriarch of an organized crime family transfers control of his clandestine empire to his reluctant son.\",\n",
      "        \"rating\": \"9.2/10\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Dark Knight\",\n",
      "        \"year\": \"2008\",\n",
      "        \"rated\": \"PG-13\",\n",
      "        \"genre\": \"Action, Adventure, Crime\",\n",
      "        \"director\": \"Christopher Nolan\",\n",
      "        \"actors\": \"Christian Bale, Heath Ledger, Aaron Eckhart\",\n",
      "        \"plot\": \"When the menace known as the Joker wreaks havoc on the city, Batman must accept one of the greatest psychological and physical tests of his ability to fight injustice.\",\n",
      "        \"rating\": \"9.0/10\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"12 Angry Men\",\n",
      "        \"year\": \"1957\",\n",
      "        \"rated\": \"G\",\n",
      "        \"genre\": \"Drama, Crime, Thriller\",\n",
      "        \"director\": \"Sidney Lumet\",\n",
      "        \"actors\": \"Henry Fonda, Jack Lemmon, Edward Binns\",\n",
      "        \"plot\": \"A dissenting juror in a murder trial struggles to convince the others that the case is not as open and\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a json object of 10 movies with their ratings.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "986e3abd-db9e-42cc-b6bc-9b5f2f2eaafd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The given code can be used to perform the following tasks.\n",
      "```\n",
      "using Newtonsoft.Json;\n",
      "using Newtonsoft.Json.Linq;\n",
      "namespace JsonMovieRatings\n",
      "{\n",
      "    class Program\n",
      "    {\n",
      "        static void Main(string[] args)\n",
      "        {\n",
      "            // Create a list of movies.\n",
      "            List<Movie> movies = new List<Movie>\n",
      "            {\n",
      "                new Movie { Name = \"The Shawshank Redemption\", Rating = 9.2M },\n",
      "                new Movie { Name = \"The Godfather\", Rating = 9.0M },\n",
      "                new Movie { Name = \"12 Angry Men\", Rating = 8.9M },\n",
      "                new Movie { Name = \"The Dark Knight\", Rating = 9.0M },\n",
      "                new Movie { Name = \"The Godfather: Part II\", Rating = 9.2M },\n",
      "                new Movie { Name = \"Schindler's List\", Rating = 9.1M },\n",
      "                new Movie { Name = \"The Good, the Bad and the Ugly\", Rating = 8.8M },\n",
      "                new Movie { Name = \"Pulp Fiction\", Rating = 8.9M },\n",
      "                new Movie { Name = \"The Lord of the Rings: The Return of the King\", Rating = 9.2M }\n",
      "            };\n",
      "            // Create a list of ratings for these movies.\n",
      "            List<decimal> ratings = new List<decimal>();\n",
      "            foreach (var movie in movies)\n",
      "            {\n",
      "                ratings.Add(movie.Rating);\n",
      "            }\n",
      "            // Combine them to make a JSON object of 10 movies with their ratings.\n",
      "            JArray jsonMovies = new JArray(movies.Take(10));\n",
      "            foreach (var rating in ratings)\n",
      "            {\n",
      "                jsonMovies.Add(new JObject {\n",
      "                    { \"Name\", movies[0].Name },\n",
      "                    { \"Rating\", rating }\n",
      "                });\n",
      "            }\n",
      "            string json = jsonMovies.ToString();\n",
      "            Console.WriteLine(json);\n",
      "            Console.ReadKey();\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "The code uses the Newtonsoft.Json library to work with JSON data. It creates a list of movies and\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write code for the following.//\n",
    "1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a json object of 10 movies with their ratings.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c5dd3bb-b46d-474f-aab3-3a7d77b849f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "movies = [\n",
      "    {\n",
      "        \"name\": \"The Shawshank Redemption\",\n",
      "        \"rating\": \"9.2\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"The Godfather\",\n",
      "        \"rating\": \"9.2\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"12 Angry Men\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"The Dark Knight\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"The Godfather: Part II\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Schindler's List\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"The Good, the Bad and the Ugly\",\n",
      "        \"rating\": \"8.8\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Pulp Fiction\",\n",
      "        \"rating\": \"8.8\"\n",
      "    }\n",
      "]\n",
      "\n",
      "ratings = [\n",
      "    {\n",
      "        \"movie_id\": 1,\n",
      "        \"rating\": 9.2\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 1,\n",
      "        \"rating\": 9.2\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 1,\n",
      "        \"rating\": 9.2\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 1,\n",
      "        \"rating\": 9.2\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 2,\n",
      "        \"rating\": 9.2\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 2,\n",
      "        \"rating\": 9.2\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 3,\n",
      "        \"rating\": 9.0\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 3,\n",
      "        \"rating\": 9.0\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 3,\n",
      "        \"rating\": 9.0\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 3,\n",
      "        \"rating\": 9.0\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 4,\n",
      "        \"rating\": 9.0\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 4,\n",
      "        \"rating\":\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a json object of 10 movies with their ratings.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d833e2a-635a-473e-8578-a023f5fafea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies =  [{\n",
      "    \"title\": \"The Shawshank Redemption\",\n",
      "    \"year\": \"1994\",\n",
      "    \"rated\": \"R\",\n",
      "    \"genre\": \"Drama, Crime, Thriller\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Godfather\",\n",
      "    \"year\": \"1972\",\n",
      "    \"rated\": \"R\",\n",
      "    \"genre\": \"Drama, Crime, Romance\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Dark Knight\",\n",
      "    \"year\": \"2008\",\n",
      "    \"rated\": \"PG-13\",\n",
      "    \"genre\": \"Action, Crime, Drama\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"12 Angry Men\",\n",
      "    \"year\": \"1957\",\n",
      "    \"rated\": \"G\",\n",
      "    \"genre\": \"Drama\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"To Kill a Mockingbird\",\n",
      "    \"year\": \"1962\",\n",
      "    \"rated\": \"G\",\n",
      "    \"genre\": \"Drama, Crime, Romance\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Lord of the Rings: The Fellowship of the Ring\",\n",
      "    \"year\": \"2001\",\n",
      "    \"rated\": \"PG-13\",\n",
      "    \"genre\": \"Action, Adventure, Fantasy\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Wizard of Oz\",\n",
      "    \"year\": \"1939\",\n",
      "    \"rated\": \"G\",\n",
      "    \"genre\": \"Fantasy, Family, Musical\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Schindler's List\",\n",
      "    \"year\": \"1993\",\n",
      "    \"rated\": \"R\",\n",
      "    \"genre\": \"Drama, History, War\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Good, the Bad and the Ugly\",\n",
      "    \"year\": \"1966\",\n",
      "    \"rated\": \"R\",\n",
      "    \"genre\": \"Western\"\n",
      "  }]\n",
      "\n",
      "Ratings = [{\n",
      "    \"title\": \"The Shawshank Redemption\",\n",
      "    \"year\": \"1994\",\n",
      "    \"rated\": \"R\",\n",
      "    \"genre\": \"Drama, Crime, Thriller\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Godfather\",\n",
      "    \"year\": \"1972\",\n",
      "    \"rated\": \"R\",\n",
      "    \"genre\": \"Drama, Crime, Romance\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Dark Knight\",\n",
      "    \"year\": \"2008\",\n",
      "    \"rated\": \"PG-13\",\n",
      "    \"genre\": \"Action, Crime, Drama\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"12 Angry Men\",\n",
      "    \"year\": \"1957\",\n",
      "    \"rated\": \"G\",\n",
      "    \"genre\": \"Drama\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"To Kill a Mockingbird\",\n",
      "    \"year\": \"1962\",\n",
      "    \"rated\": \"G\",\n",
      "    \"genre\": \"Drama, Crime, Romance\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Lord of the Rings: The Fellowship of the Ring\",\n",
      "    \"year\": \"2001\",\n",
      "    \"rated\": \"PG-13\",\n",
      "    \"genre\": \"Action, Adventure, Fantasy\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Wizard of Oz\",\n",
      "    \"year\": \"1939\",\n",
      "    \"rated\": \"G\",\n",
      "    \"genre\": \"Fantasy, Family, Musical\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Schindler's List\",\n",
      "    \"year\":\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following and provide comments.//\n",
    "1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a json object of 10 movies with their ratings.//\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c791c50-c468-4bce-a00d-1a7e0e018efc",
   "metadata": {},
   "source": [
    "*Observation: The generated code looks like working code. However, the output doesn't contain code to combine movies, their ratings into a JSON object.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "794ded7d-780c-4f29-bdd3-cc31ec6225bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "list_of_movies = [\"The Shawshank Redemption\", \"The Godfather\", \"12 Angry Men\", \"The Dark Knight\", \"Forrest Gump\", \"The Godfather Part II\", \"Schindler's List\", \"The Pianist\", \"Good Will Hunting\", \"The Lord of the Rings: The Return of the King\"]\n",
      "list_of_ratings = [4, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "\n",
      "# Create a JSON object of 10 movies with their ratings.\n",
      "json_data = {\n",
      "    \"movies\": [\n",
      "        {\"movie\": movie, \"rating\": rating}\n",
      "        for movie, rating in zip(list_of_movies, list_of_ratings)\n",
      "    ]\n",
      "}\n",
      "print(json_data)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following and provide comments.//\n",
    "1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a JSON object of 10 movies with their ratings.//\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=750))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c592f-52ef-413e-9a03-fc6bd1f4fdd8",
   "metadata": {},
   "source": [
    "*Observation 1: The generated code looks like working code. However, the output doesn't contain an important import statement, i.e., import json. While these models generate working code, you must pay close attention to small details like this and always make sure to test your code.*\n",
    "\n",
    "*Observation 2: Additionally... somehow capitalizing \"json\" gives you an appropriate code as opposed to the outputs from before.*\n",
    "\n",
    "*Observation 3: No comments are provided as instructed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e71a4d65-bca4-4952-bc5b-374e73483cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "movies = [\n",
      "    {\n",
      "        \"title\": \"The Shawshank Redemption\",\n",
      "        \"year\": \"1994\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, Crime, Thriller\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Godfather\",\n",
      "        \"year\": \"1972\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Crime, Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Dark Knight\",\n",
      "        \"year\": \"2008\",\n",
      "        \"rated\": \"PG-13\",\n",
      "        \"genre\": \"Action, Crime, Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"12 Angry Men\",\n",
      "        \"year\": \"1957\",\n",
      "        \"rated\": \"G\",\n",
      "        \"genre\": \"Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Schindler's List\",\n",
      "        \"year\": \"1993\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, History, War\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"To Kill a Mockingbird\",\n",
      "        \"year\": \"1962\",\n",
      "        \"rated\": \"G\",\n",
      "        \"genre\": \"Drama, Crime, Romance\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Good, the Bad and the Ugly\",\n",
      "        \"year\": \"1966\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Spaghetti Western, Action, Crime\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Lord of the Rings: The Return of the King\",\n",
      "        \"year\": \"2003\",\n",
      "        \"rated\": \"PG-13\",\n",
      "        \"genre\": \"Fantasy, Adventure, Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Pianist\",\n",
      "        \"year\": \"2002\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, History, War\"\n",
      "    }\n",
      "]\n",
      "\n",
      "ratings = [\n",
      "    {\n",
      "        \"user\": \"Sally\",\n",
      "        \"rating\": 5,\n",
      "        \"movie\": \"The Shawshank Redemption\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Bob\",\n",
      "        \"rating\": 4,\n",
      "        \"movie\": \"The Godfather\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Lily\",\n",
      "        \"rating\": 3,\n",
      "        \"movie\": \"The Dark Knight\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"John\",\n",
      "        \"rating\": 2,\n",
      "        \"movie\": \"12 Angry Men\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Emily\",\n",
      "        \"rating\": 4,\n",
      "        \"movie\": \"Schindler's List\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Noah\",\n",
      "        \"rating\": 1,\n",
      "        \"movie\": \"To Kill a Mockingbird\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Oliver\",\n",
      "        \"rating\": 4,\n",
      "        \"movie\": \"The Good, the Bad and the Ugly\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Elijah\",\n",
      "        \"rating\": 5,\n",
      "        \"movie\": \"The Lord of the Rings: The Return of the King\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Leo\",\n",
      "        \"rating\": 2,\n",
      "        \"movie\": \"The Pianist\"\n",
      "    }\n",
      "]\n",
      "\n",
      "jsonMovies = []\n",
      "\n",
      "for i in range(0, 10):\n",
      "    random_movie = random.choice(movies)\n",
      "    random_rating = random.choice(ratings)\n",
      "    jsonMovies.append({\n",
      "        \"title\": random_movie[\"title\"],\n",
      "        \"year\": random_movie[\"year\"],\n",
      "        \"rated\": random_rating[\"rating\"],\n",
      "        \"genre\": random_movie[\"genre\"]\n",
      "    })\n",
      "\n",
      "with open(\"movies_data.json\", \"w\") as outfile:\n",
      "    json.dump(jsonMovies, outfile)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a JSON object of 10 movies with their ratings.//\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec444d67-6691-40d2-9ec5-cd580b8255b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "*TESTING the code generated above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43a824ee-a742-458f-8d11-46307b91dbc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1702/4036044455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mrandom_movie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mrandom_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     jsonMovies.append({\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "movies = [\n",
    "    {\n",
    "        \"title\": \"The Shawshank Redemption\",\n",
    "        \"year\": \"1994\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Drama, Crime, Thriller\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Godfather\",\n",
    "        \"year\": \"1972\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Crime, Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Dark Knight\",\n",
    "        \"year\": \"2008\",\n",
    "        \"rated\": \"PG-13\",\n",
    "        \"genre\": \"Action, Crime, Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"12 Angry Men\",\n",
    "        \"year\": \"1957\",\n",
    "        \"rated\": \"G\",\n",
    "        \"genre\": \"Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Schindler's List\",\n",
    "        \"year\": \"1993\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Drama, History, War\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"To Kill a Mockingbird\",\n",
    "        \"year\": \"1962\",\n",
    "        \"rated\": \"G\",\n",
    "        \"genre\": \"Drama, Crime, Romance\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Good, the Bad and the Ugly\",\n",
    "        \"year\": \"1966\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Spaghetti Western, Action, Crime\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Lord of the Rings: The Return of the King\",\n",
    "        \"year\": \"2003\",\n",
    "        \"rated\": \"PG-13\",\n",
    "        \"genre\": \"Fantasy, Adventure, Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Pianist\",\n",
    "        \"year\": \"2002\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Drama, History, War\"\n",
    "    }\n",
    "]\n",
    "\n",
    "ratings = [\n",
    "    {\n",
    "        \"user\": \"Sally\",\n",
    "        \"rating\": 5,\n",
    "        \"movie\": \"The Shawshank Redemption\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Bob\",\n",
    "        \"rating\": 4,\n",
    "        \"movie\": \"The Godfather\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Lily\",\n",
    "        \"rating\": 3,\n",
    "        \"movie\": \"The Dark Knight\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"John\",\n",
    "        \"rating\": 2,\n",
    "        \"movie\": \"12 Angry Men\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Emily\",\n",
    "        \"rating\": 4,\n",
    "        \"movie\": \"Schindler's List\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Noah\",\n",
    "        \"rating\": 1,\n",
    "        \"movie\": \"To Kill a Mockingbird\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Oliver\",\n",
    "        \"rating\": 4,\n",
    "        \"movie\": \"The Good, the Bad and the Ugly\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Elijah\",\n",
    "        \"rating\": 5,\n",
    "        \"movie\": \"The Lord of the Rings: The Return of the King\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Leo\",\n",
    "        \"rating\": 2,\n",
    "        \"movie\": \"The Pianist\"\n",
    "    }\n",
    "]\n",
    "\n",
    "jsonMovies = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    random_movie = random.choice(movies)\n",
    "    random_rating = random.choice(ratings)\n",
    "    jsonMovies.append({\n",
    "        \"title\": random_movie[\"title\"],\n",
    "        \"year\": random_movie[\"year\"],\n",
    "        \"rated\": random_rating[\"rating\"],\n",
    "        \"genre\": random_movie[\"genre\"]\n",
    "    })\n",
    "\n",
    "with open(\"movies_data.json\", \"w\") as outfile:\n",
    "    json.dump(jsonMovies, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84801d-dac3-4bbc-8779-c00641c9edbe",
   "metadata": {},
   "source": [
    "*As observed earlier: The output doesn't contain an important import statement, i.e., import random. Again, while these models generate working code, you must pay close attention to small details like this and always make sure to test your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267a1345-6417-4682-9959-4fba4fcd09d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "movies = [\n",
    "    {\n",
    "        \"title\": \"The Shawshank Redemption\",\n",
    "        \"year\": \"1994\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Drama, Crime, Thriller\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Godfather\",\n",
    "        \"year\": \"1972\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Crime, Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Dark Knight\",\n",
    "        \"year\": \"2008\",\n",
    "        \"rated\": \"PG-13\",\n",
    "        \"genre\": \"Action, Crime, Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"12 Angry Men\",\n",
    "        \"year\": \"1957\",\n",
    "        \"rated\": \"G\",\n",
    "        \"genre\": \"Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Schindler's List\",\n",
    "        \"year\": \"1993\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Drama, History, War\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"To Kill a Mockingbird\",\n",
    "        \"year\": \"1962\",\n",
    "        \"rated\": \"G\",\n",
    "        \"genre\": \"Drama, Crime, Romance\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Good, the Bad and the Ugly\",\n",
    "        \"year\": \"1966\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Spaghetti Western, Action, Crime\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Lord of the Rings: The Return of the King\",\n",
    "        \"year\": \"2003\",\n",
    "        \"rated\": \"PG-13\",\n",
    "        \"genre\": \"Fantasy, Adventure, Drama\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Pianist\",\n",
    "        \"year\": \"2002\",\n",
    "        \"rated\": \"R\",\n",
    "        \"genre\": \"Drama, History, War\"\n",
    "    }\n",
    "]\n",
    "\n",
    "ratings = [\n",
    "    {\n",
    "        \"user\": \"Sally\",\n",
    "        \"rating\": 5,\n",
    "        \"movie\": \"The Shawshank Redemption\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Bob\",\n",
    "        \"rating\": 4,\n",
    "        \"movie\": \"The Godfather\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Lily\",\n",
    "        \"rating\": 3,\n",
    "        \"movie\": \"The Dark Knight\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"John\",\n",
    "        \"rating\": 2,\n",
    "        \"movie\": \"12 Angry Men\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Emily\",\n",
    "        \"rating\": 4,\n",
    "        \"movie\": \"Schindler's List\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Noah\",\n",
    "        \"rating\": 1,\n",
    "        \"movie\": \"To Kill a Mockingbird\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Oliver\",\n",
    "        \"rating\": 4,\n",
    "        \"movie\": \"The Good, the Bad and the Ugly\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Elijah\",\n",
    "        \"rating\": 5,\n",
    "        \"movie\": \"The Lord of the Rings: The Return of the King\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Leo\",\n",
    "        \"rating\": 2,\n",
    "        \"movie\": \"The Pianist\"\n",
    "    }\n",
    "]\n",
    "\n",
    "jsonMovies = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    random_movie = random.choice(movies)\n",
    "    random_rating = random.choice(ratings)\n",
    "    jsonMovies.append({\n",
    "        \"title\": random_movie[\"title\"],\n",
    "        \"year\": random_movie[\"year\"],\n",
    "        \"rated\": random_rating[\"rating\"],\n",
    "        \"genre\": random_movie[\"genre\"]\n",
    "    })\n",
    "\n",
    "with open(\"movies_data.json\", \"w\") as outfile:\n",
    "    json.dump(jsonMovies, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ac3b7-bdeb-42ba-ab5a-0a0c738bfab1",
   "metadata": {},
   "source": [
    "*Observation 1: a JSON file is created with the desired list. Check created files in your output drive.*\n",
    "*Observation 2: no comments were provided in the original ouput to the prompt above as we did not ask for any. Let us ask for comments or explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f414d8a8-da20-4ed4-81c1-824aea57a2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```Python\n",
      "import json\n",
      "movies = [\n",
      "    {\n",
      "        \"title\": \"The Shawshank Redemption\",\n",
      "        \"year\": \"1994\",\n",
      "        \"rating\": \"9.2\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Godfather\",\n",
      "        \"year\": \"1972\",\n",
      "        \"rating\": \"9.2\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"12 Angry Men\",\n",
      "        \"year\": \"1957\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Dark Knight\",\n",
      "        \"year\": \"2008\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Godfather: Part II\",\n",
      "        \"year\": \"1974\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Schindler's List\",\n",
      "        \"year\": \"1993\",\n",
      "        \"rating\": \"9.0\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Good, the Bad and the Ugly\",\n",
      "        \"year\": \"1966\",\n",
      "        \"rating\": \"8.9\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Lord of the Rings: The Return of the King\",\n",
      "        \"year\": \"2003\",\n",
      "        \"rating\": \"8.9\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Pulp Fiction\",\n",
      "        \"year\": \"1994\",\n",
      "        \"rating\": \"8.8\"\n",
      "    }\n",
      "]\n",
      "ratings = [\n",
      "    {\"user\": \"james\", \"score\": \"10\"},\n",
      "    {\"user\": \"john\", \"score\": \"9\"},\n",
      "    {\"user\": \"jane\", \"score\": \"8\"},\n",
      "    {\"user\": \"michelle\", \"score\": \"7\"},\n",
      "    {\"user\": \"dave\", \"score\": \"6\"},\n",
      "    {\"user\": \"larry\", \"score\": \"5\"},\n",
      "    {\"user\": \"carol\", \"score\": \"4\"},\n",
      "    {\"user\": \"sam\", \"score\": \"3\"},\n",
      "    {\"user\": \"nancy\", \"score\": \"2\"},\n",
      "    {\"user\": \"ted\", \"score\": \"1\"}\n",
      "]\n",
      "try:\n",
      "    # Create a list of dictionaries representing the movies with their ratings\n",
      "    movie_list = [\n",
      "        {\n",
      "            \"title\": movie[\"title\"],\n",
      "            \"year\": movie[\"year\"],\n",
      "            \"rating\": \"{0:.2f}\".format(rating[\"score\"])\n",
      "        }\n",
      "        for movie in movies\n",
      "        for rating in ratings\n",
      "    ]\n",
      "    # Convert the movie_list to a JSON string\n",
      "    json_data = json.dumps(movie_list)\n",
      "    # Print the JSON data\n",
      "    print(json_data)\n",
      "except Exception as e:\n",
      "    # Handle any exceptions that occur during the execution\n",
      "    print(\"An error occurred:\", str(e))\n",
      "```\n",
      "The provided code demonstrates how to create a list of movies with corresponding ratings and convert it into a JSON object. First, a list named \"movies\" is created, containing movie titles, years, and ratings. Each movie is represented as a dictionary with the relevant information. Similarly, a list named \"ratings\" is created, which holds user information along with their respective ratings for the movies. To combine the movie and rating lists, a list comprehension is used. It iterates over the \"movies\" list and for each movie, it retrieves the ratings associated with it using a nested list comprehension. The ratings are filtered to include only those ratings given by users in the \"ratings\" list. The resulting list of dictionaries represents each movie with its associated ratings. Next, the \"movie_list\" is converted to a JSON string using the \"json.dumps()\" function. This JSON representation contains the movie data in the form of a list of dictionaries. Finally, the JSON data is printed to the console. The code is wrapped in a try-except block to handle any exceptions that may occur during execution. If an exception is caught, an error message is printed. Overall, this code combines movie and rating data to create a JSON object, making it easily accessible and manipulatable for various purposes.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a JSON object of 10 movies with their ratings.//\n",
    "Explain the code.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223f124-40b2-4d06-a9b5-2faec13a16d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Observation: the prompt above generated the required code including the import statement, an output json dump file, and an explanation. Mission Accomplished.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7541042-c7b4-4b57-ad93-bad1b5cf6cde",
   "metadata": {},
   "source": [
    "OTHER EXAMPLES for Generating Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7cf5b8d-8043-4631-bc53-d2a0f1f609e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, y):\n",
      "\treturn x * y + 75\n",
      "z = multiply(2, 3)\n",
      "print(z)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"write a function to multiply two numbers and add 75 to it.//\n",
    "def multiply(\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a978920-39fa-40e1-b6f8-b118f8d05467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, y):\n",
      "\treturn x * y\n",
      "add = 75\n",
      "result = multiply(3,4) + add\n",
      "print(result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"write a function to multiply two numbers and add 75 to it. Explain the code.//\n",
    "def multiply(\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86b44e9b-0b14-4e14-9a04-0c4ff0f0f0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, y):\n",
      "\tproduct = x * y\n",
      "\treturn product\n",
      "\n",
      "add = 75\n",
      "\n",
      "result = multiply(5, 3) + add\n",
      "print(result)\n",
      "\n",
      "The provided code defines a function called multiply that takes two numbers as input and returns their product.\n",
      "\n",
      "The function multiply(x, y) calculates the product of x and y and assigns the result to a variable called product. In this case, it multiplies 5 and 3 to get 15.\n",
      "\n",
      "The code also includes an additional variable called add, which is assigned the value 75.\n",
      "\n",
      "Finally, the code calculates the sum of the product and add by adding them together. In this case, it adds 15 and 75 to get 90, which is assigned to the variable result.\n",
      "\n",
      "The result is then printed to the console.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"write a function to multiply two numbers and add 75 to it. Describe each step of the code.//\n",
    "def multiply(\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b38ec-193f-4da0-b29e-96f1b80297f0",
   "metadata": {},
   "source": [
    "*Observation: For some reason, asking for code explanations changes with the code we are asking the model to generate. Instructing with a certain phrase only works in some cases. For others cases, we require iterations before we reach a desirable output with explanations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ca0d8-fcc5-449d-966d-037757fca075",
   "metadata": {
    "tags": []
   },
   "source": [
    "***[2] Computer Code with no comments or explanations (only code)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d96a9c7d-8841-4957-b982-9ee26a0d8ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "userName = input(\"Enter your name: \")\n",
      "print(\"Hello, \" + userName + \"!\")\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate python computer code for the following use case. \n",
    "// Ask the user for their name and say \"Hello\" to them after they state their name.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc0a125f-fb98-4bb4-9665-848d68bbcf4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution:\n",
      "```\n",
      "result = 2 + 2\n",
      "print(result)\n",
      "```\n",
      "Output: 4\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write computer code to add 2 and 2.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6651c99-0bae-44d2-a076-7b4322b10b82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a=2\n",
      "b=2\n",
      "sum=a+b\n",
      "print(sum)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write computer code to add 2 and 2.//\n",
    "Avoid phrases or comments.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0c46889-a970-48ae-8b30-6881190f907e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Let the two numbers be a and b.\n",
      "The function to be formed is ab+75.\n",
      "Now,\n",
      "ab=a*b\n",
      "Substitute ab with (a*b)+75.\n",
      "(a*b)+75=ab+75\n",
      "Simplify.\n",
      "a^2+b^2+75ab=a^2+b^2+75*a*b\n",
      "Simplify further.\n",
      "2a^2+2b^2+75ab=2a^2+2b^2+75*a*b+75\n",
      "=2a^2+2b^2+75ab+75\n",
      "Hence, the function formed is ab+75.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write a function to multiply two numbers and add 75 to it.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8a1c3cd-54fe-47df-b1b5-adf5d735f834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def add_75(x, y):\n",
      "    return x*y + 75\n",
      "print(add_75(2,3))\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write a python function to multiply two numbers and add 75 to it.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3ce759c-833e-4ef0-a04c-3307836d217b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def add_75(x, y):\n",
      "\treturn x*y + 75\n",
      "#Call the function with the values 3 and 5 as arguments.\n",
      "result = add_75(3, 5)\n",
      "print(result)\n",
      ">>> 50\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write a python function to multiply two numbers and add 75 to it.//\n",
    "Exclude code comments or explanations.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e246b10-136d-46fb-9c26-e9223cdee18e",
   "metadata": {},
   "source": [
    "*Observation: Hallucination*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "049259b5-1b0b-4eec-908e-bf589311035d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def add_75(x, y):\n",
      "    return x * y + 75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write a python function to multiply two numbers and add 75 to it.//\n",
    "Avoid code comments or explanations.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b061c-e768-4239-bda8-e7e1a400c1c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "*works*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f1950f9-ca8f-4f5a-9ea9-f29a13520357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT T1.StudentName FROM Students AS T1 JOIN Departments AS T2 ON T1.DepartmentId = T2.DepartmentId WHERE T2.DepartmentName = \"Computer Science\";\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Table departments, columns = [DepartmentId, DepartmentName]//\n",
    "Table students, columns = [DepartmentId, StudentId, StudentName]//\n",
    "Create a MySQL query for all students in the Computer Science department//\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f1dd9-27f7-49b8-882d-ceab04e23dec",
   "metadata": {},
   "source": [
    "* THE TRAVELING SALESMAN PROBLEM: Given a set of cities and the distance between every pair of cities, the problem is to find the shortest possible route that visits every city exactly once and returns to the starting point.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10f00f5a-84c9-43f5-a29a-fb61a66443e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"1. Create a graph to represent the problem. The graph should have nodes that represent cities and edges that represent possible routes between cities. 2. Define a cost function for each edge in the graph. The cost function should take into account the distance between the two cities and any other factors that might affect the cost of traveling between them. 3. Use an algorithm, such as Dijkstra's algorithm, to search for the shortest path through the graph. The algorithm will start with an initial set of nodes and will iteratively add nodes to the set that have the lowest cost until it has found the shortest path. 4. Calculate the total cost of the shortest path and return it as the solution to the problem.\"\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate code to solve the traveling salesman problem.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09d5438d-1192-4780-96e4-23c0415b7528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the Python code to solve the traveling salesman problem.\n",
      "``` Python\n",
      "import networkx as nx\n",
      "import matplotlib.pyplot as plt\n",
      "try:\n",
      "    # Create a directed graph\n",
      "    G = nx.DiGraph()\n",
      "    # Add edges to the graph\n",
      "    G.add_edges_from([('A', 'B'), ('A', 'C'), ('B', 'D'), \n",
      "                      ('B', 'E'), ('C', 'D'), ('D', 'F'), \n",
      "                      ('E', 'F'), ('E', 'G')])\n",
      "    # Find the shortest path using Dijkstra's algorithm\n",
      "    path = nx.shortest_path(G, 'A', 'F')\n",
      "    # Print the shortest path\n",
      "    print(\"Shortest path:\", path)\n",
      "    # Visualize the graph\n",
      "    nx.draw(G, cmap=plt.get_cmap('viridis'), node_color=path, with_labels=True)\n",
      "    plt.show()\n",
      "except Exception as e:\n",
      "    print(\"An error occurred:\", str(e))\n",
      "```\n",
      "The above Python code uses the 'networkx' library to solve the traveling salesman problem. It creates a directed graph 'G' with several edges representing cities. The'shortest_path()' function is then used to find the shortest path between two cities, in this case, 'A' and 'F'. The shortest path is printed, and the graph 'G' is visualized using 'nx.draw()' with the specified colors and labels.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate Python code to solve the traveling salesman problem.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f296cea-dfa9-4e0d-bd23-24af3f484631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def dist(p1, p2):\n",
      "    return math.sqrt((p2[0] - p1[0])**2 + (p1[1] - p2[1])**2)\n",
      "def tsp(c):\n",
      "    n = len(c)\n",
      "    if n < 2:\n",
      "        return 0  # or whatever...\n",
      "    if n == 2:\n",
      "        return dist(c[0], c[1])\n",
      "    else:\n",
      "        # First pass: order cities by distance from the starting city.\n",
      "        c = sorted(c, key=lambda p: dist(c[0], p))\n",
      "        # Second pass: backtrack from the farthest city.\n",
      "        total = 0\n",
      "        best = [c[0]]  # Current best route\n",
      "        for p in c[1:]:\n",
      "            total += dist(best[-1], p)\n",
      "            best.append(p)\n",
      "            if len(best) == n:\n",
      "                return total\n",
      "        return -1  # or whatever...\n",
      "print(tsp([(1, 5), (3, 9), (7, 10), (12, 13), (14, 15)]))\n",
      "print(tsp([(1, 5), (3, 9), (7, 10), (12, 13), (14, 20)]))\n",
      "print(tsp([(1, 5), (3, 9), (7, 10), (12, 13), (14, 20), (21, 22), (23, 0)]))\n",
      ">>> 5\n",
      ">>> 14\n",
      ">>> 11\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate Python code to solve the traveling salesman problem.//\n",
    "Avoid code comments or explanations.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbf278-a009-4a1c-a37e-3af1a694cd1c",
   "metadata": {},
   "source": [
    "*Observation: still includes comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4363ee05-9f4b-4974-80d9-c4c1349f62ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def dist(p1, p2):\n",
      "    return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)\n",
      "def tsp(c):\n",
      "    n = len(c)\n",
      "    if n < 2: return 0\n",
      "    if n == 2: return dist(c[0], c[1])\n",
      "    paths = [[]] * (n)\n",
      "    # Filling initial distance of all the nodes from the first city.\n",
      "    fill(paths, 0, c[0])\n",
      "    # Finding the minimum distance for all possible combinations of two cities.\n",
      "    min_dist = float('inf')\n",
      "    for i in range(1, n):\n",
      "        for j in range(i+1, n):\n",
      "            # Calculating the distance between the cities.\n",
      "            dist_ij = dist(c[i-1], c[j-1]) + fill(paths, j, c[j])\n",
      "            if dist_ij < min_dist:\n",
      "                min_dist = dist_ij\n",
      "                best_path = [c[i-1]] + paths[j]\n",
      "    return min_dist\n",
      "def fill(paths, city, current_dist):\n",
      "    if current_dist > 10**6: return current_dist\n",
      "    if city in paths[city]: return paths[city][current_dist]\n",
      "    paths[city][current_dist] = fill(paths, city, current_dist+1)\n",
      "    return paths[city][current_dist]\n",
      "# Input city list\n",
      "c = [(1, 3), (2, 5), (4, 8), (5, 7), (6, 2), (7, 6), (8, 1), (9, 9)]\n",
      "# Calling tsp function\n",
      "print(tsp(c))\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate Python code to solve the traveling salesman problem.//\n",
    "Do not include code comments or explanations.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9845fe5b-b1d4-4b90-be63-1104a4008371",
   "metadata": {},
   "source": [
    "*Observation: still includes comments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7962beb-3aba-41ee-9ad3-362b19fc89df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def dist(p1, p2):\n",
      "    return math.sqrt((p2[0]-p1[0])**2 + (p2[1]-p1[1])**2)\n",
      "def tsp(c):\n",
      "    n = len(c)\n",
      "    if n < 2: return 0\n",
      "    dist_mat = [[0 for j in range(n)] for i in range(n)]\n",
      "    for i in range(n):\n",
      "        for j in range(n):\n",
      "            dist_mat[i][j] = dist(c[i], c[j])\n",
      "    path_sum = 0\n",
      "    seen = set()\n",
      "    to_visit = [1]\n",
      "    while to_visit:\n",
      "        cur = to_visit.pop()\n",
      "        if cur in seen: continue\n",
      "        seen.add(cur)\n",
      "        path_sum += cur\n",
      "        for next in c:\n",
      "            new_dist = dist_mat[cur][next] + dist(cur, next)\n",
      "            if new_dist < dist_mat[next][cur]:\n",
      "                dist_mat[next][cur] = new_dist\n",
      "                to_visit.append(next)\n",
      "    return path_sum\n",
      "print(tsp([(1,3),(3,5),(5,7),(7,2)]))\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate Python code to solve the traveling salesman problem.//\n",
    "ONLY generate code. Avoid comments, phrases, or explanations.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2321311-a705-4ea7-a6de-9cff093c7fb4",
   "metadata": {},
   "source": [
    "*Observation: No comments, explanations, or phrases. Mission Accomplished.*\n",
    "*NOTE: All code related to the traveling salesman problem to be tested*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e082b-4f53-447d-87e6-aa4b6fb5a185",
   "metadata": {},
   "source": [
    "* PSO - Particle swarm optimization is one of the bio-inspired algorithms and it is a simple one to search for an optimal solution in the solution space. It is different from other optimization algorithms in such a way that only the objective function is needed and it is not dependent on the gradient or any differential form of the objective. It also has very few hyperparameters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35f72e8c-a29d-4143-9c07-42354518cd60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def PSO(particles, c1, c2, w, xopt, gopt, gbest, Niter, fig, ax, iter, best_fitness, best_x, best_y):\n",
      "    \"\"\"\n",
      "    @param particles: A list of Particle objects.\n",
      "    @param c1: The first constraint.\n",
      "    @param c2: The second constraint.\n",
      "    @param w: The inertia weight.\n",
      "    @param xopt: The current best solution.\n",
      "    @param gopt: The gradient of the objective function.\n",
      "    @param gbest: The best solution found so far.\n",
      "    @param Niter: The maximum number of iterations.\n",
      "    @param fig: The figure to plot.\n",
      "    @param ax: The axis to plot on.\n",
      "    @param iter: The current iteration.\n",
      "    @param best_fitness: The fitness of the best solution.\n",
      "    @param best_x: The best solution's coordinates.\n",
      "    @param best_y: The best solution's coordinates.\n",
      "    @return: The new best solution.\n",
      "    \"\"\"\n",
      "    for i in range(Niter):\n",
      "        for particle in particles:\n",
      "            particle.update_velocity(xopt, c1, c2, w, gopt)\n",
      "        for particle in particles:\n",
      "            particle.update_position(xopt, c1, c2)\n",
      "        fitness_values = [particle.fitness for particle in particles]\n",
      "        best_fitness = min(fitness_values)\n",
      "        idx = fitness_values.index(best_fitness)\n",
      "        best_x = particles[idx].x\n",
      "        best_y = particles[idx].y\n",
      "        if fig is not None:\n",
      "            ax.cla()\n",
      "            ax.plot(best_x, best_y, 'ro')\n",
      "            ax.axis('equal')\n",
      "            fig.canvas.draw()\n",
      "        if best_fitness < best_fitness:\n",
      "            print(f\"Iteration: {iter}, Fitness: {best_fitness}\")\n",
      "            best_fitness = best_fitness\n",
      "            best_x = best_x\n",
      "            best_y = best_y\n",
      "        iter += 1\n",
      "    return best_x, best_y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate Python code to solve particle swarm optimization.//\n",
    "ONLY generate code. Avoid comments, phrases, or explanations.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a354e12-3ad9-438c-809e-ba26a9bb9a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The particle swarm optimization (PSO) is a population-based optimization algorithm, which is inspired by the social behavior of bird flocking and fish schooling. The following code can be used to solve particle swarm optimization problems:\n",
      "```Python\n",
      "import sys\n",
      "from math import sqrt, log, exp\n",
      "from random import random, gauss\n",
      "from collections import deque\n",
      "# Initialize particle\n",
      "def initParticle(N, c1, c2):\n",
      "    return [random()*(c2-c1) + c1 for i in range(N)]\n",
      "# Calculate fitness value\n",
      "def fitness(X):\n",
      "    return sum([pow(X[i]-X[j], 2) for i, j in zip(X, P)])\n",
      "# Update velocity\n",
      "def updateVelocity(P, V, F, C1, C2):\n",
      "    for i, p in enumerate(P):\n",
      "        v = [0, 0]\n",
      "        for j, vj in enumerate(V):\n",
      "            v[j] = C1 * vj + C2 * random()\n",
      "        P[i][:] = [p[0] + v[0], p[1] + v[1]]\n",
      "# Update position\n",
      "def updatePosition(P, X):\n",
      "    for i, p in enumerate(P):\n",
      "        P[i][:] = [p[0] + X[i][0], p[1] + X[i][1]]\n",
      "# Main function\n",
      "def PSO(N, F, C1, C2, ITER):\n",
      "    # Initialize particle\n",
      "    P = [initParticle(N, 0, 10) for i in range(N)]\n",
      "    # Initialize velocity\n",
      "    V = [initParticle(N, 0, 1) for i in range(N)]\n",
      "    # Initialize best fitness and best position\n",
      "    BestFitness = sys.maxsize\n",
      "    BestPosition = [0, 0]\n",
      "    # Initialize iteration counter\n",
      "    counter = 0\n",
      "    while counter < ITER:\n",
      "        # Calculate fitness value for each particle\n",
      "        Fnew = [fitness(X) for X in P]\n",
      "        # Update velocity\n",
      "        updateVelocity(P, V, Fnew, C1, C2)\n",
      "        # Update position\n",
      "        updatePosition(P, BestPosition)\n",
      "        # Check the best fitness\n",
      "        if Fnew[0] < BestFitness:\n",
      "            BestFitness = Fnew[0]\n",
      "            BestPosition = [P[i][0] for i in range(N)]\n",
      "        # Print current position and fitness\n",
      "        print(\"Iteration: \", counter, \"Fitness: \", BestFitness)\n",
      "        print(BestPosition)\n",
      "        counter += 1\n",
      "    # Print best position\n",
      "    print(\"Best Position: \", BestPosition)\n",
      "# Call main function\n",
      "PSO(3, 2, 0.9, 0.1, 100)\n",
      ">>>Iteration: 0 Fitness: 10.0000\n",
      ">>>[0.0000, 0.0000]\n",
      ">>>Iteration: 1 Fitness: 9.9900\n",
      ">>>[0.0000, 0.0000]\n",
      ">>>Iteration: 2 Fitness: 9.9800\n",
      ">>>[0.0000, 0.0000]\n",
      ">>>...\n",
      ">>>Iteration: 98 Fitness: 0.0000\n",
      ">>>[0.0000, 0.0000]\n",
      ">>>Iteration: 99 Fitness: 0.0000\n",
      ">>>[0.0000, 0.0000]\n",
      ">>>Iteration: 100 Fitness: 0.0000\n",
      ">>>[0.0000, 0.0000]\n",
      ">>>Best Position:  [0.0000, 0.0000]\n",
      "```\n",
      "The given code uses the 'initParticle()' function to initialize a list of 'N' particles. The 'fitness()' function calculates the fitness value for each particle based on the difference between the current position and the target position. The 'updateVelocity()' function updates the velocity of each particle using the current position, velocity, and fitness values. The 'updatePosition()' function updates the position of each particle using the updated velocity. The 'PSO()' function is the main function that performs the particle swarm optimization. It initializes the particles, velocities, and best fitness and position values. It iterates a specified number of times, updating the positions and velocities of the particles based on the fitness function and the current positions and velocities.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate Python code to solve particle swarm optimization.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5680253a-ea05-4f14-ba80-0ce5335a94a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \"\"\"\n",
      "    Quicksort algorithm for sorting an array of integers.\n",
      "    Args:\n",
      "        a: A list of integers.\n",
      "    Returns:\n",
      "        A sorted list of integers.\n",
      "    \"\"\"\n",
      "    less = []\n",
      "    equal = []\n",
      "    greater = []\n",
      "    if a == []: \n",
      "        return []\n",
      "    else:\n",
      "        a.sort()\n",
      "        pivot = a[0]\n",
      "        for x in a:\n",
      "            if x <= pivot:\n",
      "                less.append(x)\n",
      "            elif x > pivot:\n",
      "                greater.append(x)\n",
      "            else:\n",
      "                equal.append(x)\n",
      "        return quicksort(less) + [pivot] + quicksort(greater)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"complete the following computer code. ONLY generate code. Avoid comments, phrases, or explanations. //\n",
    "def quicksort(a):\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d690d81-0d4d-4019-a9ae-48f72a88f3a5",
   "metadata": {},
   "source": [
    "Observation: Model still includes a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5cc59017-d914-41fb-9a3c-d2538d4699a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \"\"\"\n",
      "    Quicksort algorithm for sorting an array of integers.\n",
      "    Args:\n",
      "        a (list): A list of integers to be sorted.\n",
      "    Returns:\n",
      "        list: A sorted list of integers.\n",
      "    \"\"\"\n",
      "    if a == []: \n",
      "        return []\n",
      "    else:\n",
      "        pivot = a[0]\n",
      "        lesser = quicksort([x for x in a[1:] if x < pivot])\n",
      "        greater = quicksort([x for x in a[1:] if x >= pivot])\n",
      "        return lesser + [pivot] + greater\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the following computer code. //\n",
    "def quicksort(a):\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5a323-412d-49e3-92e2-fa941923e971",
   "metadata": {},
   "source": [
    "Observation: Model still includes comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dfd276ab-1f84-4f57-9b1b-214d318df844",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// QuickSort algorithm in Python\n",
      "def quicksort(a):\n",
      "    less = []\n",
      "    equal = []\n",
      "    greater = []\n",
      "    if len(a) > 1:\n",
      "        pivot = a[0]\n",
      "        for x in a:\n",
      "            if x < pivot:\n",
      "                less.append(x)\n",
      "            elif x == pivot:\n",
      "                equal.append(x)\n",
      "            elif x > pivot:\n",
      "                greater.append(x)\n",
      "        # Recursive calls for left and right halves\n",
      "        quicksort(less)\n",
      "        quicksort(greater)\n",
      "    return less + equal + greater\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the following computer code. ONLY generate code. /\n",
    "def quicksort(a): /\n",
    "Avoid comments, phrases, or explanations.\n",
    "\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8485958a-3f84-445a-9ef0-403ccccef28e",
   "metadata": {},
   "source": [
    "Observation: Model still includes a comment at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1318b9d3-52a8-4348-84fe-804dab1f1e17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if a is not None and a < 0:  a.sort()  return a[0]\n",
      "n = int(input())\n",
      "a = list(map(int, input().split()))\n",
      "quicksort(a)\n",
      "print(a[0])\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Complete the following computer code without using comments. //\n",
    "def quicksort(a): \"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01c8dbd4-bbd9-4d74-a75f-2ec029dd8d91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"import sys\n",
      "from math import sqrt, log, pi, cos, sin\n",
      "from random import random, gauss\n",
      "from collections import deque\n",
      "def fitness(p):\n",
      "    return sum([(cos(a)*sin(b))**2 for (a,b) in zip(p,p[1:])])\n",
      "def evaluate(c, x, r):\n",
      "    return sum([(c[i]-x[i])**2 for i in range(len(c))])**0.5\n",
      "def initParticle(population, numParticles, fitnessFunction):\n",
      "    return [random() for i in range(numParticles)]\n",
      "def updateParticle(population, particle, numParticles, fitnessFunction):\n",
      "    for i in range(numParticles):\n",
      "        c = population[i]\n",
      "        v = [random()-0.5 for i in range(len(c))]\n",
      "        w = [fitnessFunction(c+v) - fitnessFunction(c)]\n",
      "        r = [random()-0.5 for i in range(len(w))]\n",
      "        p = [c+r[i]*v[i] for i in range(len(c))]\n",
      "        if fitnessFunction(p) > fitnessFunction(particle):\n",
      "            particle = p\n",
      "    return particle\n",
      "def main():\n",
      "    numParticles = int(sys.argv[1])\n",
      "    numIterations = int(sys.argv[2])\n",
      "    populationSize = 100\n",
      "    population = initParticle(populationSize, numParticles, fitness)\n",
      "    bestFitness = fitness(population)\n",
      "    bestPosition = population\n",
      "    print(\"Best fitness:\", bestFitness)\n",
      "    print(\"Best position:\", bestPosition)\n",
      "    for i in range(numIterations):\n",
      "        population = [updateParticle(population, particle, numParticles, fitness) \\\n",
      "            for particle in population]\n",
      "        fitnesses = [fitness(p) for p in population]\n",
      "        if fitnesses[0] < bestFitness:\n",
      "            bestFitness = fitnesses[0]\n",
      "            bestPosition = population[fitnesses.index(bestFitness)]\n",
      "        print(\"Iteration:\", i, \"Fitness:\", fitnesses[0])\n",
      "    print(\"Best fitness:\", bestFitness)\n",
      "    print(\"Best position:\", bestPosition)\n",
      "if __name__ == '__main__':\n",
      "    main()\"\n",
      "(generated code)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Generate Python code to solve particle swarm optimization. Do not use comments.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86df3900-aff4-444c-a89a-862c05dba61f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, y):\n",
      "\treturn x*y + 75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write a Python function to multiply two numbers and add 75 to it. Do not use comments.//\n",
    "def multiply(\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1ec89dd5-f80b-466d-9e74-03d60c1eb3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "movies = [\n",
      "    {\n",
      "        \"title\": \"The Shawshank Redemption\",\n",
      "        \"year\": \"1994\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, Crime, Thriller\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Godfather\",\n",
      "        \"year\": \"1972\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Crime, Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Dark Knight\",\n",
      "        \"year\": \"2008\",\n",
      "        \"rated\": \"PG-13\",\n",
      "        \"genre\": \"Action, Crime, Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"12 Angry Men\",\n",
      "        \"year\": \"1957\",\n",
      "        \"rated\": \"G\",\n",
      "        \"genre\": \"Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Schindler's List\",\n",
      "        \"year\": \"1993\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, History, War\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"To Kill a Mockingbird\",\n",
      "        \"year\": \"1962\",\n",
      "        \"rated\": \"G\",\n",
      "        \"genre\": \"Drama, Crime, Romance\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Good, the Bad and the Ugly\",\n",
      "        \"year\": \"1966\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Spaghetti Western, Action, Crime\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Lord of the Rings: The Return of the King\",\n",
      "        \"year\": \"2003\",\n",
      "        \"rated\": \"PG-13\",\n",
      "        \"genre\": \"Fantasy, Adventure, Drama\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"The Pianist\",\n",
      "        \"year\": \"2002\",\n",
      "        \"rated\": \"R\",\n",
      "        \"genre\": \"Drama, History, War\"\n",
      "    }\n",
      "]\n",
      "\n",
      "ratings = [\n",
      "    {\n",
      "        \"user\": \"Sally\",\n",
      "        \"rating\": 5,\n",
      "        \"movie\": \"The Shawshank Redemption\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Bob\",\n",
      "        \"rating\": 4,\n",
      "        \"movie\": \"The Godfather\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Lily\",\n",
      "        \"rating\": 3,\n",
      "        \"movie\": \"The Dark Knight\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"John\",\n",
      "        \"rating\": 2,\n",
      "        \"movie\": \"12 Angry Men\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Emily\",\n",
      "        \"rating\": 4,\n",
      "        \"movie\": \"Schindler's List\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Noah\",\n",
      "        \"rating\": 1,\n",
      "        \"movie\": \"To Kill a Mockingbird\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Oliver\",\n",
      "        \"rating\": 4,\n",
      "        \"movie\": \"The Good, the Bad and the Ugly\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Elijah\",\n",
      "        \"rating\": 5,\n",
      "        \"movie\": \"The Lord of the Rings: The Return of the King\"\n",
      "    },\n",
      "    {\n",
      "        \"user\": \"Leo\",\n",
      "        \"rating\": 2,\n",
      "        \"movie\": \"The Pianist\"\n",
      "    }\n",
      "]\n",
      "\n",
      "jsonMovies = []\n",
      "\n",
      "for i in range(0, 10):\n",
      "    random_movie = random.choice(movies)\n",
      "    random_rating = random.choice(ratings)\n",
      "    jsonMovies.append({\n",
      "        \"title\": random_movie[\"title\"],\n",
      "        \"year\": random_movie[\"year\"],\n",
      "        \"rated\": random_rating[\"rating\"],\n",
      "        \"genre\": random_movie[\"genre\"]\n",
      "    })\n",
      "\n",
      "with open(\"movies_data.json\", \"w\") as outfile:\n",
      "    json.dump(jsonMovies, outfile)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "1. Create a list of movies. //\n",
    "2. Create a list of ratings for these movies. //\n",
    "3. Combine them to make a JSON object of 10 movies with their ratings.//\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7e907a7-4481-4d10-84c1-48919788c8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def is_leap(year):\n",
      "  return year % 4 == 0 and year % 100!= 0\n",
      "print(is_leap(2024))\n",
      "print(is_leap(2020))\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "Calculate leap years.//\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "98b6e17a-7d95-46cb-ad52-92a45db414f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tif a == []:\n",
      "\t\treturn []\n",
      "\telse:\n",
      "\t\tpivot = a[0]\n",
      "\t\tless = quicksort([x for x in a[1:] if x < pivot])\n",
      "\t\tgreater = quicksort([x for x in a[1:] if x >= pivot])\n",
      "\t\treturn less + [pivot] + greater\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "def quicksort(a):\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "65351f6b-4b54-4501-8522-ec32aca2b691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def PSO(particles, c1, c2, w1, w2, maxiter, xbest, f, fitness_function):\n",
      "    for i in range(maxiter):\n",
      "        for j in range(len(particles)):\n",
      "            pbest = particles[j]\n",
      "            pbest_fitness = fitness_function(pbest)\n",
      "            r1 = random.random()\n",
      "            r2 = random.random()\n",
      "            c1 = c1 * w1 * r1\n",
      "            c2 = c2 * w2 * r2\n",
      "            particles[j].x = pbest.x + c1\n",
      "            particles[j].y = pbest.y + c2\n",
      "            f_new = fitness_function(particles[j])\n",
      "            if f_new < pbest_fitness:\n",
      "                pbest = particles[j]\n",
      "                pbest_fitness = f_new\n",
      "                xbest = pbest.x\n",
      "                ybest = pbest.y\n",
      "        print(xbest, ybest, pbest_fitness)\n",
      "    return xbest, ybest, pbest_fitness\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "Particle Swarm Optimization.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eeca1d2f-9a03-4b72-aef2-8d7108585a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def dist(p1, p2):\n",
      "    return math.sqrt((p2[0]-p1[0])**2 + (p2[1]-p1[1])**2)\n",
      "def tsp(n, cities):\n",
      "    dist = {}\n",
      "    for i in range(n):\n",
      "        dist[i] = [9999999, i]\n",
      "    dist[0] = [0, 0]\n",
      "    totaldist = 0\n",
      "    path = []\n",
      "    found = False\n",
      "    # trying all possible paths\n",
      "    while not found:\n",
      "        found = True\n",
      "        for i in range(n):\n",
      "            if dist[i][0] > dist[i+1][0] + dist(cities[i], cities[i+1]):\n",
      "                found = False\n",
      "                break\n",
      "        if found:\n",
      "            totaldist += dist[i][0]\n",
      "            path.append(i)\n",
      "    return totaldist, path\n",
      "n, m = map(int, input().split())\n",
      "cities = []\n",
      "for i in range(m):\n",
      "    x, y = map(int, input().split())\n",
      "    cities.append([x, y])\n",
      "dist1, path1 = tsp(n, cities)\n",
      "dist2, path2 = tsp(n, cities[1:])\n",
      "if dist1 < dist2:\n",
      "    print(\"First\")\n",
      "else:\n",
      "    print(\"Second\")\n",
      "if dist1 == dist2:\n",
      "    print(path1)\n",
      "    print(path2)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "Traveling Salesman Problem.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d1ce957b-1c40-4a94-a6c2-caffb084a075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a = 25\n",
      "b = 50\n",
      "c = a * b + 75\n",
      "print(c)\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write python code for the following.//\n",
    "Multiply two numbers and add 75 to it.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e4cc0e26-25b5-4f0e-9840-ff516b9371db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#include <stdio.h>\n",
      "\n",
      "int main() {\n",
      "   int x, y, sum;\n",
      "\n",
      "   printf(\"Enter two numbers: \");\n",
      "   scanf(\"%d %d\", &x, &y);\n",
      "\n",
      "   sum = x * y + 75;\n",
      "\n",
      "   printf(\"The sum is: %d\", sum);\n",
      "\n",
      "   return 0;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write C++ code for the following.//\n",
    "Multiply two numbers and add 75 to it.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d4b682f-66b3-4aed-8366-15db754090b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "print(\"What is your name? \")\n",
      "name = input()\n",
      "print(\"Hello, \" + name + \"!\")\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\"Write Python code for the following.//\n",
    "Ask the user for their name and say \"Hello\" to them after they state their name.\"\"\"\n",
    "\n",
    "print(prompt(prompt_data, temperature=0, topP=0.1, maxTokenCount=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2a416-0e21-436b-8992-b7d749623b0e",
   "metadata": {},
   "source": [
    "**remove comments; remove summary;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb685b-b149-40c4-9dad-6fbeab64aa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
